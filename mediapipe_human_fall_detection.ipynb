{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pz4zIa0NwPss"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import mediapipe as mp\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Function to load and preprocess images with Mediapipe\n",
        "def load_and_preprocess_images(directory, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    mp_hands = mp.solutions.hands\n",
        "    hands = mp_hands.Hands()\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "            img = cv2.imread(os.path.join(directory, filename))\n",
        "            img = cv2.resize(img, (64, 64))\n",
        "\n",
        "            # Use Mediapipe to extract hand landmarks or other information\n",
        "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            results = hands.process(img_rgb)\n",
        "\n",
        "            # Modify this part based on your specific use case with Mediapipe\n",
        "            if results.multi_hand_landmarks:\n",
        "                for hand_landmarks in results.multi_hand_landmarks:\n",
        "                    # Process hand landmarks as needed\n",
        "                    # Example: hand_landmarks.landmark contains the 3D coordinates of hand landmarks\n",
        "\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "\n",
        "    hands.close()  # Close the mediapipe hands module\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load and preprocess fall and non-fall images with Mediapipe\n",
        "fall_images, fall_labels = load_and_preprocess_images(\"/content/drive/MyDrive/Dataset/fall_dataset\", label=1)\n",
        "non_fall_images, non_fall_labels = load_and_preprocess_images(\"/content/drive/MyDrive/Dataset/non_fall_dataset\", label=0)\n",
        "\n",
        "# Concatenate fall and non-fall images and labels\n",
        "all_images = np.concatenate([fall_images, non_fall_images], axis=0)\n",
        "all_labels = np.concatenate([fall_labels, non_fall_labels], axis=0)\n",
        "\n",
        "# Shuffle the dataset\n",
        "indices = np.arange(all_images.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "all_images = all_images[indices]\n",
        "all_labels = all_labels[indices]\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "all_images = all_images / 255.0\n",
        "\n",
        "# Build and compile the model as before\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(weight_decay), input_shape=(64, 64, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)),\n",
        "    layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, weight_decay=1e-5)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(all_images, all_labels, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Save the trained model to Google Drive\n",
        "model.save(\"/content/drive/MyDrive/fall_detection_model.h5\")\n"
      ]
    }
  ]
}